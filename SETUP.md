# Setup & Installation Guide

## System Requirements

- **Python**: 3.7+
- **OS**: Windows, macOS, Linux
- **CPU**: Any modern processor (no GPU needed!)
- **RAM**: 4GB minimum, 8GB recommended
- **Storage**: 200MB for code + 5MB for trained model

## Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

This installs:
- `opencv-python` - Image processing
- `scikit-learn` - SVM classifier
- `numpy` - Numerical computing
- `tqdm` - Progress bars

## Step 2: Prepare Your Data

Ensure you have the dataset in place:
```
Cracks-main/
â”œâ”€â”€ annotations/          # YOLO format annotations (*.txt)
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ positive/        # Images with cracks
â”‚   â”œâ”€â”€ negative/        # Images without cracks
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
```

The system expects images and annotations to match by name:
- Image: `11336_1.jpg`
- Annotation: `11336_1.txt`

## Step 3: Train the Model

### Quick Training (5-10 minutes)
```bash
python quick_start.py --train
```

This trains on 300 random samples for fast prototyping.

### Full Training
```bash
python crack_detector_cv.py --train --max-samples 1000 \
  --annotations Cracks-main/annotations \
  --images Cracks-main/dataset/positive
```

**Training Output:**
- Model saved as `crack_detector_model.pkl` (~2-5MB)
- Contains trained SVM classifier and feature scaler

### What Happens During Training

1. **Load Images & Annotations** (YOLO format)
   - Read normalized bounding boxes
   - Convert to pixel coordinates
   - Extract positive patches (64Ã—64) from crack regions
   - Generate negative patches randomly

2. **Preprocess Images**
   - Convert to grayscale
   - Apply Canny edge detection (50, 150 thresholds)

3. **Extract Features**
   - Compute HOG (Histogram of Oriented Gradients)
   - 16Ã—16 cell size, 8Ã—8 block size
   - 9 orientation bins
   - Results in ~2016 features per patch

4. **Train Classifier**
   - Normalize features (StandardScaler)
   - Train SVM with RBF kernel
   - Parameters: C=1.0, gamma='scale'
   - Compute decision boundaries

**Training Time:**
- 200 samples: 3-5 minutes
- 500 samples: 5-8 minutes
- 1000 samples: 8-15 minutes

**Memory Usage:**
- Peak during training: 300-500MB
- Model on disk: 2-5MB

## Step 4: Detect Cracks

### Single Image Detection
```bash
python quick_start.py --detect path/to/image.jpg
```

Creates output:
- `image_cracks_detected.jpg` - Visualization with bounding boxes

### Batch Detection
```bash
python batch_utils.py --batch Cracks-main/dataset/positive \
  --output detection_results --max-images 50
```

Creates output:
- `detection_results/` folder with all visualizations
- `detection_results/report.txt` - Summary statistics

### Detection with Custom Threshold
```bash
# Lower threshold = more detections (lower precision)
python quick_start.py --detect image.jpg --confidence 0.4

# Higher threshold = fewer detections (higher precision)  
python quick_start.py --detect image.jpg --confidence 0.7
```

**What Happens During Detection:**

1. **Load Image**
   - Read as grayscale
   - Image size preserved (any resolution)

2. **Sliding Window Scanning**
   - 64Ã—64 patches, stride of 16 pixels
   - Left-to-right, top-to-bottom
   - ~80-150 patches per typical image

3. **Feature Extraction & Classification**
   - Apply Canny edges to each patch
   - Extract HOG features
   - SVM prediction with confidence score
   - Filter by confidence threshold

4. **Post-Processing**
   - Non-Maximum Suppression (NMS)
   - Remove overlapping boxes (IOU > 0.3)
   - Keep highest confidence detections

5. **Visualization**
   - Draw bounding boxes
   - Display confidence scores
   - Save annotated image

**Detection Speed:**
- 640Ã—480 image: 2-5 seconds
- 1280Ã—720 image: 5-10 seconds

## Step 5: Run Demo

See all features in action:
```bash
python demo.py
```

Runs 6 demonstrations:
1. Model information
2. Edge detection visualization
3. Single image detection
4. Batch detection
5. Confidence threshold analysis
6. HOG feature extraction

Generates demo output files showing each step.

## Advanced Usage

### Custom Image Directory
```bash
python crack_detector_cv.py --train \
  --annotations /custom/path/annotations \
  --images /custom/path/images
```

### Tune Confidence Threshold
Find optimal value for your use case:
```python
from crack_detector_cv import CrackDetectorCV

detector = CrackDetectorCV()
detector.load_model()

# Try different thresholds
for threshold in [0.3, 0.5, 0.7, 0.9]:
    img, detections = detector.detect_cracks(
        'test.jpg', 
        confidence_threshold=threshold
    )
    print(f"Threshold {threshold}: {len(detections)} detections")
```

### Batch Processing with Python
```python
from pathlib import Path
from crack_detector_cv import CrackDetectorCV

detector = CrackDetectorCV()
detector.load_model()

for img_file in Path('images/').glob('*.jpg'):
    img, detections = detector.detect_cracks(str(img_file))
    print(f"{img_file.name}: {len(detections)} cracks")
```

### Use Different Window Size
```python
# Modify for smaller/larger patches
detector = CrackDetectorCV()
detector.window_size = (32, 32)  # For small cracks
# or
detector.window_size = (128, 128)  # For large regions
```

## Troubleshooting

### Error: "No module named 'cv2'"
```bash
pip install opencv-python
```

### Error: "Model file not found"
Train the model first:
```bash
python quick_start.py --train
```

### Error: "Image not found"
Check image path and ensure file exists:
```bash
ls -la path/to/image.jpg
```

### Slow detection speed
- Use smaller images
- Increase stride size (edit source code)
- Reduce confidence threshold

### Poor detection accuracy
- Train on more samples
- Adjust Canny thresholds (50, 150)
- Tune SVM parameters (C, gamma)
- Try different window sizes

### Out of memory during training
- Reduce `max_samples`
- Process in batches
- Close other applications

## Performance Optimization

### Faster Training
```bash
# Use fewer samples
python quick_start.py --train
# Modifies: max_samples=300

# Or in code
max_samples = 100  # Even faster
```

### Faster Detection
1. Increase stride (line ~195 in crack_detector_cv.py):
   ```python
   step_size = 32  # Instead of 16 (2x faster)
   ```

2. Use higher confidence threshold:
   ```bash
   python quick_start.py --detect image.jpg --confidence 0.7
   ```

3. Resize image first:
   ```python
   import cv2
   img = cv2.imread('image.jpg')
   img_small = cv2.resize(img, (640, 480))
   cv2.imwrite('temp.jpg', img_small)
   ```

### Reduce Model Size
The model is already compact (~2-5MB). To reduce further:
```python
# Use LinearSVC instead of SVC
from sklearn.svm import LinearSVC
detector.model = Pipeline([
    ('scaler', StandardScaler()),
    ('svm', LinearSVC(C=1.0, max_iter=1000))
])
```

## File Structure

After setup:
```
Crack_project/
â”œâ”€â”€ crack_detector_cv.py          # Main detector class
â”œâ”€â”€ quick_start.py               # Quick training/detection
â”œâ”€â”€ batch_utils.py               # Batch processing
â”œâ”€â”€ demo.py                      # Interactive demo
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ README_CV.md                 # System overview
â”œâ”€â”€ SETUP.md                     # This file
â”œâ”€â”€ crack_detector_model.pkl     # Trained model (generated)
â”œâ”€â”€ Cracks-main/
â”‚   â”œâ”€â”€ annotations/
â”‚   â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ ...
â””â”€â”€ detections/                  # Output directory (generated)
```

## Next Steps

1. âœ“ Install dependencies
2. âœ“ Train the model
3. âœ“ Detect cracks in images
4. âœ“ Review results
5. â†’ Tune parameters for your use case
6. â†’ Deploy to production

## Support

For issues:
1. Check error message carefully
2. Review relevant section above
3. Check file paths and permissions
4. Verify dataset format (YOLO annotations)
5. Try with smaller dataset first

## Performance Checklist

- [ ] Dependencies installed (`pip list`)
- [ ] Dataset prepared and verified
- [ ] Model trained successfully
- [ ] Test detection on sample image
- [ ] Review output visualizations
- [ ] Benchmark speed (demo.py)
- [ ] Adjust parameters if needed
- [ ] Ready for production use!

Good luck! ðŸš€
